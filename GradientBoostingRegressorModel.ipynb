{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a9a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "import pandas as pd\n",
    "\n",
    "file_id = '1DP3G49DWVUaRBkn7wssPi6CfY1pTmTQP'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c626968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting original data\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Assigning data split\n",
    "y = df['Borg']\n",
    "X = df.drop('Borg', axis = 1)\n",
    "\n",
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting with test_size = 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004f11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1aa5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing and Training a Regressor for SelectFromModel\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Creating pipeline with Feature Selection\n",
    "regressor_model = Pipeline([\n",
    "    ('feature_sel', SelectFromModel(gbr)),\n",
    "    ('regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "params_grid = {\n",
    "\n",
    "    # Feature Selection Parameter\n",
    "    'feature_sel__threshold' : [\"mean\", \"median\"], # out of 3 runs, we choose mean\n",
    "\n",
    "    # Regressor Parameter\n",
    "    'regressor__n_estimators' : [100, 200], # High = better accuracy but overfits\n",
    "    'regressor__max_features' : [0.5, 0.1], # 0.5, 'sqrt', 'log2', 0.1, \n",
    "    'regressor__min_samples_leaf' : [10, 30], # 10\n",
    "    'regressor__max_depth' : [8, 30], # 8\n",
    "    'regressor__subsample' : [0.7, 0.8], # 0.8\n",
    "    'regressor__min_samples_split' : [20, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "830f51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gbr_CV = GridSearchCV(regressor_model, params_grid, cv = 3, n_jobs = 3, scoring = 'neg_mean_squared_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32227d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best GridScore is -2.5025215173260253\n",
      "The best parameters are {'feature_sel__threshold': 'mean', 'regressor__max_depth': 30, 'regressor__max_features': 0.5, 'regressor__min_samples_leaf': 30, 'regressor__min_samples_split': 20, 'regressor__n_estimators': 200, 'regressor__subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Fitting into training data\n",
    "gbr_CV.fit(X_train, y_train)\n",
    "\n",
    "# Printing Scores\n",
    "print('The best GridScore is', gbr_CV.best_score_)\n",
    "print('The best parameters are', gbr_CV.best_params_)\n",
    "\n",
    "# Retraining model with best parameters\n",
    "regressor_model.set_params(**gbr_CV.best_params_)\n",
    "regressor_model.fit(X_train, y_train)\n",
    "\n",
    "# Getting predictions \n",
    "y_pred = regressor_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Metrics\n",
    "training_score = regressor_model.score(X_train, y_train)\n",
    "testing_score = regressor_model.score(X_test, y_test)\n",
    "meanSquaredError = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Training Score is \", training_score)\n",
    "print(\"Testing Score is,\", testing_score)\n",
    "print(\"Mean Squared Error is\", meanSquaredError)\n",
    "\n",
    "# 300 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5381f7",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor (GBR)\n",
    "Gradient Boosting Regressor (GBR) is a type of ensemble machine learning technique. Ensemble learning combines multiple machine learning model to produce better accuracies compared to a single model. GBR uses multiple decision trees where each new tree is trained to reduce the remaining error via residual errors.\n",
    "\n",
    "### Brief Introduction\n",
    "In our parameters, n_estimator is the number of tree we add into the model. We start of with 50 to 150 n_estimators. Increasing the number of trees only slightly increases accuracy. We set it at 200 is where we see the largest jump in accuracy. The training score is especially high followed with a lower testing score. The rest of the parameter now serves to reduce overfitting.\n",
    "\n",
    "### Feature Selection\n",
    "The implementation of feature selection, SelectFromModel(), serves to reduce dimensionalty by selecting features by scores from a pre-trained model and compares it to the threshold specified. \n",
    "\n",
    "### Hyperparameter Tuning\n",
    "The parameters chosen serve to increase accuracy. Although overfitting is an obvious issue here,\n",
    "\n",
    "### GridSearch\n",
    "We then perform a grid search with cross validation of 3 because of our huge dataset and it reduces computation time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
